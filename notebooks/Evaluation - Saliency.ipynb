{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#Basic Imports\n",
    "import os,sys\n",
    "os.chdir('/home/asebaq/MSMatch')\n",
    "\n",
    "from tqdm import tqdm,trange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas\n",
    "\n",
    "from datasets.ssl_dataset import SSL_Dataset\n",
    "from datasets.data_utils import get_data_loader\n",
    "from utils import get_model_checkpoints\n",
    "from utils import net_builder\n",
    "from utils import clean_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary visualization code\n",
    "# Original code from https://github.com/utkuozbulak/pytorch-cnn-visualizations\n",
    "# slightly modified it to fit our needs\n",
    "from external.visualizations.guided_backprop import GuidedBackprop\n",
    "from external.visualizations.misc_functions import convert_to_grayscale,get_positive_negative_saliency\n",
    "from external.visualizations.smooth_grad import generate_smooth_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to the runs to load\n",
    "folder = \"/home/asebaq/MSMatch/trained_models/rgb/saved_models_rgb/fixmatch/eurosat_rgb/FixMatch_archefficientnet-b0_batch16_confidence0.95_lr0.03_uratio7_wd0.0005_wu1.0_seed0_numlabels4000_optSGD\" #Path to the runs to load \n",
    "\n",
    "sort_criterion = \"numlabels\" # Accepted net, numlabels\n",
    "seed_wanted = 0 # Seed wanted (the others will be filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home\n"
     ]
    }
   ],
   "source": [
    "checkpoints, run_args = get_model_checkpoints(folder)\n",
    "if os.name == 'nt':\n",
    "       [print(_.split(\"\\\\\")[1]) for _ in checkpoints];\n",
    "else:\n",
    "       [print(_.split(\"/\")[1]) for _ in checkpoints];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/asebaq/MSMatch/trained_models/rgb/saved_models_rgb/fixmatch/eurosat_rgb/FixMatch_archefficientnet-b0_batch16_confidence0.95_lr0.03_uratio7_wd0.0005_wu1.0_seed0_numlabels4000_optSGD/model_best.pth'] [{'dataset': 'eurosat_rgb', 'net': 'efficientnet-b0', 'batch': 16, 'confidence': 0.95, 'lr': 0.03, 'uratio': 7, 'wd': 0.0005, 'wu': 1.0, 'seed': 0, 'numlabels': 4000, 'opt': 'SGD', 'iterations': 40000}]\n"
     ]
    }
   ],
   "source": [
    "print(checkpoints, run_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 11/11 [00:11<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "_eval_dset = SSL_Dataset(\"eurosat_rgb\", train=False,  data_dir=\"/home/asebaq/MSMatch/data/\", seed=seed_wanted)\n",
    "eval_dset = _eval_dset.get_dset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ RUNNING  /home/asebaq/MSMatch/trained_models/rgb/saved_models_rgb/fixmatch/eurosat_rgb/FixMatch_archefficientnet-b0_batch16_confidence0.95_lr0.03_uratio7_wd0.0005_wu1.0_seed0_numlabels4000_optSGD/model_best.pth  -----------------\n",
      "{'dataset': 'eurosat_rgb', 'net': 'efficientnet-b0', 'batch': 16, 'confidence': 0.95, 'lr': 0.03, 'uratio': 7, 'wd': 0.0005, 'wu': 1.0, 'seed': 0, 'numlabels': 4000, 'opt': 'SGD', 'iterations': 40000}\n",
      "Using not pretrained model efficientnet-b0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                      | 0/2700 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (66,66) (3,65,65) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m param_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;66;03m#nr of images to sample\u001b[39;00m\n\u001b[1;32m     76\u001b[0m param_sigma_multiplier \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;66;03m#noise strength\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_smooth_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ^This parameter\u001b[39;49;00m\n\u001b[1;32m     78\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mparam_n\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mparam_sigma_multiplier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m result \u001b[38;5;241m=\u001b[39m result[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m64\u001b[39m] \u001b[38;5;66;03m#some padding happens in the network, we discard\u001b[39;00m\n\u001b[1;32m     84\u001b[0m result \u001b[38;5;241m=\u001b[39m convert_to_grayscale(result)\n",
      "File \u001b[0;32m~/MSMatch/external/visualizations/smooth_grad.py:47\u001b[0m, in \u001b[0;36mgenerate_smooth_grad\u001b[0;34m(Backprop, prep_img, target_class, param_n, param_sigma_multiplier)\u001b[0m\n\u001b[1;32m     45\u001b[0m     vanilla_grads \u001b[38;5;241m=\u001b[39m Backprop\u001b[38;5;241m.\u001b[39mgenerate_gradients(noisy_img, target_class)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# Add gradients to smooth_grad\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     smooth_grad \u001b[38;5;241m=\u001b[39m \u001b[43msmooth_grad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvanilla_grads\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Average it out\u001b[39;00m\n\u001b[1;32m     49\u001b[0m smooth_grad \u001b[38;5;241m=\u001b[39m smooth_grad \u001b[38;5;241m/\u001b[39m param_n\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (66,66) (3,65,65) "
     ]
    }
   ],
   "source": [
    "\n",
    "saliency = {} #will contain saliency maps for all runs\n",
    "correct_prediction = {} # will contain predictions\n",
    "numbers_to_skip  = []\n",
    "N = 2700 # how many images should be looked at\n",
    "\n",
    "#Start with num labels = 50, will break if smallest not 50!\n",
    "runs = list(zip(checkpoints,run_args))\n",
    "runs.reverse()\n",
    "\n",
    "#Iterate over runs\n",
    "for path, args in runs:\n",
    "    print(\"------------ RUNNING \", path, \" -----------------\")\n",
    "    print(args)\n",
    "    args[\"data_dir\"] = \"/home/asebaq/MSMatch/data/\"\n",
    "    args[\"use_train_model\"] = False\n",
    "    args[\"load_path\"] = path\n",
    "    saliency[args[\"numlabels\"]] = []\n",
    "    correct_prediction[args[\"numlabels\"]] = []\n",
    "    \n",
    "    if args[\"seed\"] != seed_wanted:\n",
    "        continue\n",
    "    \n",
    "    # Load the model and dataset\n",
    "    checkpoint_path = os.path.join(args[\"load_path\"])\n",
    "    checkpoint = torch.load(checkpoint_path,map_location='cuda:0')\n",
    "    load_model = (checkpoint[\"train_model\"] if args[\"use_train_model\"] else checkpoint[\"eval_model\"])\n",
    "    _net_builder = net_builder(args[\"net\"],False,{})\n",
    "    \n",
    "    net = _net_builder(num_classes=_eval_dset.num_classes, in_channels=_eval_dset.num_channels)\n",
    "    net.load_state_dict(load_model)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "    net.eval()\n",
    "\n",
    "    eval_loader = get_data_loader(eval_dset, 1, num_workers=1) #note batchsize is manually set to 1 here\n",
    "    label_encoding = _eval_dset.label_encoding\n",
    "    inv_transf = _eval_dset.inv_transform\n",
    "    \n",
    "    # Init saliency computation algorithm\n",
    "    cam = GuidedBackprop(net)\n",
    "    \n",
    "    idx = 0 #current image index\n",
    "    image_original = [] # to store original images\n",
    "    \n",
    "    \n",
    "    for image, target in tqdm(eval_loader):\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        \n",
    "        # Check prediction\n",
    "        logit = net(image)\n",
    "        correct = logit.cpu().max(1)[1].eq(target).sum().numpy()\n",
    "                        \n",
    "        # Check if correct result for num_labels 50\n",
    "        if args[\"numlabels\"] == 50:\n",
    "            if correct:\n",
    "                numbers_to_skip.append(idx)\n",
    "                idx = idx + 1\n",
    "                continue\n",
    "            else:\n",
    "                idx = idx + 1\n",
    "                \n",
    "        if idx in numbers_to_skip:\n",
    "            idx = idx + 1\n",
    "            continue\n",
    "        else:\n",
    "            idx = idx + 1\n",
    "            \n",
    "        correct_prediction[args[\"numlabels\"]].append(correct)\n",
    "        \n",
    "        image_original.append(inv_transf(image[0].transpose(0,2).cpu().numpy()).transpose(0,2).numpy())\n",
    "        \n",
    "\n",
    "        # Use smooth grad by sampling the gradients with some noise added to image to get a smoother output\n",
    "        param_n = 100 #nr of images to sample\n",
    "        param_sigma_multiplier = 2 #noise strength\n",
    "        result = generate_smooth_grad(cam,  # ^This parameter\n",
    "                                           image,\n",
    "                                           target,\n",
    "                                           param_n,\n",
    "                                           param_sigma_multiplier)\n",
    "\n",
    "        result = result[:,0:64,0:64] #some padding happens in the network, we discard\n",
    "        result = convert_to_grayscale(result)\n",
    "        result, _ = get_positive_negative_saliency(result) #we only use positive saliency maps\n",
    "        saliency[args[\"numlabels\"]].append(result[0])\n",
    "\n",
    "        if idx > N:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results\n",
    "np.save(\"saliency.npy\",saliency)\n",
    "np.save(\"image_original.npy\",image_original)\n",
    "np.save(\"correct_prediction.npy\",correct_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load results\n",
    "saliency = np.load(\"saliency.npy\")\n",
    "image_original = np.load(\"image_original.npy\")\n",
    "correct_prediction = np.load(\"correct_prediction.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_examples(images,saliency,numlabels=[50,100,500,1000,2000,3000],indices=[2]):\n",
    "    \"\"\" Small function to plot the results\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(15 * len(numlabels) / 6, 1.5*len(indices)), dpi=300)\n",
    "    offset = len(numlabels) + 1\n",
    "    images = np.asarray(images)\n",
    "    for plot_nr,idx in enumerate(indices):\n",
    "        ax = fig.add_subplot(len(indices), offset, offset*plot_nr+1, xticks=[], yticks=[])\n",
    "        img = images[idx]\n",
    "        if np.max(img) > 1.5:\n",
    "            img = img / 255\n",
    "        plt.imshow(img)\n",
    "\n",
    "        for nl_idx,nl in enumerate(numlabels):\n",
    "            ax = fig.add_subplot(len(indices), offset, offset*plot_nr+2+nl_idx, xticks=[], yticks=[])\n",
    "            sal = np.flipud(saliency[nl][idx])\n",
    "            plt.contourf(sal,cmap=\"gnuplot2\")\n",
    "    plt.savefig(\"saliency.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "indices_to_plot = np.arange(110,120)\n",
    "# print(correct_prediction[3000][20:20])\n",
    "plot_examples(image_original,saliency,numlabels=[50,3000],indices=indices_to_plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
